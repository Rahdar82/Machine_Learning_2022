{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2551be1",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "    <h1 align=\"center\">Logistic Regression</h1>\n",
    "    <h3 align=\"center\">Mohammad Rahdar</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44c289",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Logistic regression is a statistical method used for *binary classification*, which means it is used to predict the probability of a binary outcome (such as whether a customer will buy a product or not) based on one or more predictor variables. It's called \"logistic\" because it models the probability of the outcome using a logistic function.\n",
    "\n",
    "In logistic regression, the dependent variable is binary, meaning it has only two possible outcomes (e.g., 0 or 1, yes or no). The independent variables can be continuous, categorical, or a mix of both. The goal of logistic regression is to find the best-fitting model to describe the relationship between the independent variables and the probability of the binary outcome.\n",
    "\n",
    "The logistic regression model calculates the odds of the event occurring (e.g., the odds of a customer buying a product) and then transforms these odds into probabilities using the logistic function (also known as the sigmoid function). The logistic function ensures that the predicted probabilities range between 0 and 1.\n",
    "\n",
    "Logistic regression is widely used in various fields such as finance, healthcare, marketing, and social sciences for tasks such as predicting customer churn, classifying spam emails, diagnosing diseases, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31b4f",
   "metadata": {},
   "source": [
    "## Mathematical Representation\n",
    "\n",
    "In logistic regression, we start with a linear equation:\n",
    "\n",
    "$$ z = b + w_1x_1 + w_2x_2 + \\ldots + w_nx_n $$\n",
    "\n",
    "where:\n",
    "- $ z $ is the linear combination of the predictor variables weighted by their coefficients.\n",
    "- $ b $ is the intercept term.\n",
    "- $ w_1, w_2, \\ldots, w_n $ are the coefficients associated with each predictor variable $ x_1, x_2, \\ldots, x_n $ respectively.\n",
    "\n",
    "This linear combination $z$ is then transformed into a probability using the logistic (sigmoid) function:\n",
    "\n",
    "$$ P(y=1|X) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "where:\n",
    "- $ P(y=1|X) $ is the probability that the dependent variable $ y $ equals 1 given the values of the predictor variables $ X $.\n",
    "- $ e $ is the base of the natural logarithm (approximately equal to 2.71828).\n",
    "\n",
    "### Model Interpretation\n",
    "\n",
    "- The logistic function ensures that the predicted probability $P(y=1|X) $ falls between 0 and 1.\n",
    "- If the predicted probability is closer to 1, it indicates a higher likelihood of the event $ y=1 $ occurring.\n",
    "- If the predicted probability is closer to 0, it indicates a lower likelihood of the event $ y=1 $ occurring.\n",
    "\n",
    "### Model Training\n",
    "\n",
    "The logistic regression model is trained by estimating the coefficients $ b, w_1, w_2, \\ldots, w_n $ that best fit the observed data. This is typically done using maximum likelihood estimation (MLE) or gradient descent optimization techniques.\n",
    "\n",
    "### Decision Boundary\n",
    "\n",
    "In binary classification problems, logistic regression predicts the class label based on a decision boundary. For example, in a two-dimensional space with two predictor variables, the decision boundary is a line separating the instances of different classes (e.g., class 0 and class 1).\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Logistic regression models are evaluated using metrics such as accuracy, precision, recall, F1-score, and the area under the ROC curve (AUC-ROC), depending on the specific requirements of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4effc34",
   "metadata": {},
   "source": [
    "## Using scikit-learn for Logistic Regression\n",
    "\n",
    "[Scikit-learn (sklearn)](https://scikit-learn.org/stable/) is a popular machine learning library in Python that provides various tools for building and evaluating machine learning models. Logistic regression implementation in sklearn is straightforward and easy to use.\n",
    "\n",
    "### 1. Import Necessary Libraries\n",
    "\n",
    "First, you need to import the required libraries. For logistic regression, you'll need `sklearn.linear_model` and possibly other libraries depending on your specific requirements.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "\n",
    "### 2. Prepare Your Data\n",
    "Before fitting a logistic regression model, you need to prepare your data. This typically involves splitting your data into features (X) and the target variable (y), and possibly performing preprocessing steps such as scaling or encoding categorical variables.\n",
    "\n",
    "### 3. Create and Fit the Logistic Regression Model\n",
    "Next, you'll create an instance of the LogisticRegression class and fit the model to your training data.\n",
    "\n",
    "```python\n",
    "logistic_regression = LogisticRegression() # Create an instance of LogisticRegression\n",
    "logistic_regression.fit(X_train, y_train)  # Fit the model to the training data\n",
    "```\n",
    "Parameter `solver` in `LogisticRegression()` is the algorithm to use in the optimization problem. Default is `'lbfgs'`. To choose a solver, you might want to consider the following aspects:\n",
    "* For small datasets, `'liblinear'` is a good choice, whereas `'sag'` and `'saga'` are faster for large ones.\n",
    "* For multiclass problems, only `'newton-cg'`, `'sag'`, `'saga'` and `'lbfgs'` handle multinomial loss.\n",
    "* `'liblinear'` is limited to one-versus-rest schemes.\n",
    "* The choice of the algorithm depends on the penalty chosen: Supported penalties by solver:\n",
    "    * `'newton-cg'` - [`'l2'`, `'none'`]\n",
    "    * `'lbfgs'` - [`'l2'`, `'none'`]\n",
    "    * `'liblinear'` - [`'l1'`, `'l2'`]\n",
    "    * `'sag'` - [`'l2'`, ‘none’]\n",
    "    * `'saga'` - [`'elasticnet'`, `'l1'`, `'l2'`, `'none'`]\n",
    "\n",
    "### 4. Make Predictions\n",
    "Once the model is trained, you can use it to make predictions on new data.\n",
    "```python\n",
    "y_pred = logistic_regression.predict(X_test) # Make predictions on the test data\n",
    "```\n",
    "### 5. Evaluate the Model\n",
    "Finally, you'll want to evaluate the performance of your logistic regression model using appropriate evaluation metrics such as accuracy, precision, recall, F1-score, or the area under the ROC curve (AUC-ROC).\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) # Calculate accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred)) # Generate a classification report\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77508dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df3adf",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0004e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.arange(1,11).reshape(-1, 1)    # x has two dimensions\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X, y, marker='x', s=70)\n",
    "plt.xticks(np.arange(1,11))\n",
    "plt.yticks([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff6bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06596258]\n",
      "[[0.39989911]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X, y)\n",
    "\n",
    "b = model.intercept_\n",
    "w = model.coef_\n",
    "\n",
    "print(b)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47d3b6",
   "metadata": {},
   "source": [
    "The following code snippet plots a logistic regression line along with the data points and decision boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca78822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision boundary = 2.67\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjNklEQVR4nO3deZzNZf/H8ddlxmRNN6MoMrS4baUxSCOpJCQq2aKior2U6heP6r7vEhHRqlVD2VXWlCU02YdsyZKMEt0MkRsNZq7fH9eMMJNm5pwz37O8n4/Hecwx33Gdzyzerrm+12KstYiISPAq4nUBIiJyegpqEZEgp6AWEQlyCmoRkSCnoBYRCXLRgWg0NjbWxsXFBaJpEZGwtGLFijRrbfncrgUkqOPi4khJSQlE0yIiYckYs+2vrmnoQ0QkyCmoRUSCnIJaRCTIKahFgtzB9GP81VYP1loOph9Tmx62GYgaT6WgFgliB9OP0fHdxTw/fX2OMLDW8vz09XR8d3G+wkBt+q/NQNSYm78NamPMCGPMLmPMOp9eSUTyrURMFPXjyvLhwtSTwiA7BD5cmEr9uLKUiIlSmx60GYgac5OX6XlJwBvAKJ9eSUTyzRjDc61rAvDhwlQAnmtd83gIdE+M47nWNTHGqE0P2gxEjbm+Tl62OTXGxAHTrbW189JoQkKC1TxqEf85sYeWzdcQUJv+a9Mf7RljVlhrE3K75rcxamNMT2NMijEmZffu3f5qVsRvmiY1pWlSU6/LKJATe27ZfO2pqU3/tRmIGk/kt6C21r5rrU2w1iaUL5/rKkgRKaDsHtuJcruBpTa9aTMQNZ5Isz5EgtyJv1Z3T4xj64BWdE+My3EDS21602YgajxVQPb6EBH/ODUEsn+dzu0GVl5/zVab/mszEDXm5m+D2hgzFmgKxBpjtgP/stZ+UOBXFJE8O3Qkg+Wpe3PcmDoxDJan7uXQkQxKnpG3fpfa9F+bgagxN3ma9ZFfmvUhwSj7RuL8bvM9rSO/DqYfo0RMVK49MmttgUJAbfqvTX+1d7pZHxr6EAlyp/tHbowpUE9NbfqvzUDUeCrdTBQRCXIKahGRIKegFhHx1bFj8N13MHo0PPUU7N3r1+Y1Ri0ikh9Hj8LatbBiBaxc6d6uXQt//OGux8RAu3bQsKHfXlJBLSLyV6yF1FRYssQ9li2DVav+DOUyZSA+Hh54AC67DC69FP75Tyha1K9lKKhFRLIdPep6yd98AwsXwqJF8N//umslSkC9evDgg1C/PiQkQLVq4Kf9PE5HQS0ikevIEVi6FObPh6+/dsF86JC7dsEFcP310KgRXH451K4N0d5EpoJaRCJHZiasXg2zZ8Pcua7nfOiQ6xVfcgncfTc0aQKNG0OFCl5Xe5yCWkTC265dMGsWzJzpAjp7G+ZatVwwX3ONC+eyZb2t8zQU1CISXqx1N/ymTYPp0yElxb2vfHk3lHHdddCsGZx7rteV5pmCWkRC39GjsGABfPYZTJkCv/zihjMuvxyefx5atnSzMoqE5tIRBbWIhKb0dDeUMXEiTJ0K+/ZB8eLQogW0aQOtWsHZZ3tdpV8oqEUkdBw96m4Cjh0LkyfD77/DWWe5YG7Xzg1plCjhdZV+p6AWkeBmrZtC99FHMGECpKW5hSbt2kGHDu5mYEyM11UGlIJaRILTTz/ByJEuoDdvhmLFoG1buO02d1PwjDO8rrDQKKhFJHikp8Onn8KIEW6Iw1po2hT69HE96DPP9LpCTyioRcR7GzfCe+9BUhLs2QNVqsBzz8Gdd0LVql5X5zkFtYh449gxN9f5zTdd7zk6Gm66CXr2hGuvDdmpdIGgoBaRwrVnj+s9v/UW/PwzVK4M/fq5VYJBtGw7mCioRaRwbNgAw4bBqFFw+LCbrfHaa9C6tWebHYUKfXVEJHCsdRsfvfyyG+Y44wy4/XZ45BGoU8fr6kKGglpE/M9amDED+veHxYuhXDl3c/DBB8NmtWBhUlCLiP9kZMCkSS6g16xxszfeeAO6dw/LFYOFRbdVRcR3GRluWXedOtCpk1vqPWqUW6jy4IMKaR8pqEWk4DIz3aZIdeq4FYNFisD48bBunRuL9vPZgZFKQS0i+Wet2+u5Xj2334Yxbh+ONWvcnzUH2q/01RSR/Fm0yJ2IcuONcOCA24tjzRpo314BHSD6qopI3mzaBDffDImJ8MMPMHw4fP89dO0KUVFeVxfWNOtDRE4vLc2dkjJ8uNuYv18/6NULSpb0urKIoaAWkdwdPeqm1v3nP26I49574d//1jxoDyioRSSnL790veYNG9zez0OGuFO7xRMaoxaRP6Wmuh3sWrT4c3e7mTMV0h5TUIuI27D/xRehZk13YOyAAW4udOvWbuqdeEpDHyKRbt48uO8+N6ujXTsYOtRtPSpBQz1qkUiVlgbdurntRo8edUMckyYppIOQglok0lgLY8ZAjRowerQ7j3DdOjcuLUFJQx8ikeTnn+H++90WpA0awPvva1/oEKAetUgksNaFcq1abkx66FC3FFwhHRLUoxYJd9u3wz33uLnRV1/tArtaNa+rknxQj1okXFnr9oSuVQuSk91p33PmKKRDkHrUIuEoLc0t+f70U7jySkhKUkCHMPWoRcLNzJlQu7bbL3rQIDcmrZAOaQpqkXBx+LA73btVK7dx0vLl8OST2oI0DCioRcLB2rVuut3rr7vNlJYtg0su8boq8RMFtUgosxbeftuF9O7dbthj6FAoVszrysSPFNQioeq339zxV/ffD1dd5Y7D0urCsKSgFglFy5dDfDxMmQIvvwyff64N/cOYgloklFgLr73mzi3MzIRvvoEnntChsmFO312RUPH779ChAzz6qBvi+PZbaNjQ66qkECioRULBunVQvz589pmbGz1lCpQt63VVUki0MlEk2I0ZAz16QOnSMHeuu3EoEUU9apFgdfSomxPdpYu7cbhypUI6QqlHLRKMdu1y49ELFrjVhoMHQ9GiXlclHlFQiwSblBS4+Wa3sdJHH0HXrl5XJB7T0IdIMBk92u12V6QILFyokBZAQS0SHDIy4KmnXDA3bOh61fHxXlclQUJDHyJe+/136NzZrS584AEYNkzj0XISBbWIl378EW68ETZtguHD4b77vK5IgpCCWsQrX38Nt9ziloLPmuXOMxTJhcaoRbyQlATNmkFsLCxdqpCW01JQixSmzEzo0we6d4cmTWDJErjoIq+rkiCnoQ+RwnL4MNxxB0yaBD17whtv6Kah5ImCWqQw7NoFbdu6YY7Bg+Hxx8EYr6uSEKGgFgm0DRvcgbO//gqffOJWHYrkg4JaJJCSk11PumhRmD/fnW0okk+6mSgSKBMmuJkdZ5/tbhoqpKWAFNQi/mYtDBkCHTu6cF60CKpW9boqCWEKahF/ysyExx5z5xi2bw+zZ+skFvGZglrEX/74Azp1gldfdRv+jxsHxYp5XZWEAd1MFPGHffvcTcOvv3bT73r39roiCSMKahFf7djhTgXfsMHtJ33bbV5XJGFGQS3ii40b4frrYc8et01ps2ZeVyRhSEEtUlDLlrmFLFFR7mxDbfQvAaKbiZLDW2+9RdWqVSlWrBj16tUjOTn5tB+fmpqKMSbH44svviikij3w5Zdux7syZdz0O4W0BJCCWk4yfvx4Hn30Ufr27cu3337LFVdcQcuWLfnpp5/+9u9+8cUX7Ny58/jjmmuuKYSKPTB2rNvs/6KL3LmGF1zgdUUS5hTUIW7UqFGUK1eO9PT0k97fpUsX2rRpk+/2XnnlFbp160aPHj2oUaMGr7/+OhUrVmT48OF/+3fLlStHhQoVjj9iYmLy/fpB7403oEsXaNTIDXdUqOB1RRIBFNQhrn379mRmZjJlypTj79u/fz+fffYZd999N8nJyZQqVeq0j/79+wNw5MgRVqxYQfPmzU96jebNm7No0aK/reWWW27h7LPPJjExkUmTJvn3E/WatfDvf8PDD0ObNm7oo0wZr6uSCKGbiSGuePHidOnShREjRtChQwcAxowZw5lnnskNN9zA0aNHWbVq1WnbKJu1ci4tLY2MjAzOOeeck66fc845zJkz5y//fqlSpRg8eDCJiYlER0czdepUOnbsyMiRI+natatvn2AwyMyERx91velu3eC99yBa/3Sk8OinLQz06NGD+Ph4tm/fTqVKlRgxYgR33nkn0dHRREdHc+GFF+arPXPKPsnW2hzvO1FsbCy9T1jgkZCQQFpaGoMGDQr9oD561IXzmDFuEcugQVBEv4hK4dJPXBi49NJLiY+PJykpiXXr1pGSksJdd90FkK+hj9jYWKKiovj1119Pan/Xrl05etl/p2HDhmzevNk/n6BXDh92e0ePGQP9+8PLLyukxRPqUYeJHj16MGjQINLS0khMTKR69eqA693mdegjJiaGevXqMXv2bNq3b3/8+uzZs2nXrl2+6lm1ahUVK1bM3ycRTPbvd2PRycnw9ttw771eVyQRTEEdJjp37szjjz/O8OHDefvtt4+/v3jx4vka+nj88ce5/fbbadCgAYmJibz99tvs2LGD++677/jH9OnTh2XLljF37lwARo4cSdGiRbnssssoUqQI06ZN480332TgwIH++wQL0+7dbkn4mjVuKl7Hjl5XJBFOQR0mSpcuTYcOHZg4ceLxm4oF0bFjR/bs2UO/fv3YuXMntWvX5vPPP6dKlSrHP2bnzp1s2bLlpL/Xr18/tm3bRlRUFBdffDEjRowIzfHp7dvhuusgNRWmTHErD0U8Zqy1fm80ISHBpqSk+L1dOb2WLVtSqVIl3nvvPa9LCUpNk5oCML/b/Nw/YPNmF9J798KMGXDllYVWm4gxZoW1NiG3a+pRh4G9e/cyZ84cZs2axerVq70uJzStXetCOiMD5s2DevW8rkjkOAV1GIiPj2fv3r3079+f2rVre11O6Fm6FFq2hBIlXEjXqOF1RSInUVCHgdTUVK9LCF3z5rl9OypUgDlzIC7O64pEctCkUIlc06a5nnTVqm4ankJagpSCWiLT2LFuMcsll7jNlUJ5zreEPQW1RJ5333U74DVuDHPn6pRwCXoKaokoHb742a0ybNkSZs6E0qW9LknkbxX6zcSmTZvmeF+HDh144IEHOHToEK1yWWDQrVs3unXrRlpaGrfeemuO6/fffz8dO3bk559/5vbbb89xvXfv3tx4441s3LiRe3NZCvzMM8/QrFkzVq1aRa9evXJc79+/P1dccQWLFi2ib9++Oa4PGzaMunXrMmfOHPr165fj+jvvvEP16tWZNm0aQ4YMyXH9o48+onLlyowfPz7XfZ8nTZpEbGwsSUlJJCUl5bj++eefU6JECd566y0mTJiQ4/r8+fMBGDx4MNOnTz/pWvHixZk5cyYAL7zwwvHVhtnKlSvHJ598ArgViYsXLz7peqVKlfj4448B6NWrV47l6hdffDHvvvsuAD179mTTpk0nXa9bty7Dhg0DoGvXrmzfvv2k640aNWLAgAEAtGvXjj179px0/dprr+XZZ58F3Dzyw4cPn3S9devWPPHEE2AtrYYv4YFl6dChA3z0EYTjftkSltSjlvCXmQmPPcZTy9KZcWUFt8mSQlpCiFYmSnjLyICePWHECCY2P483O13A/O4LvK5KJAetTJTIdOQIdO0KEyfCv/7Fm1XmwWn21RYJVhr6kPB06BDcdJML6SFD3DFaCmkJUepRS/j5/Xe32jA52U3F69HD64pEfKKglvCSluam3q1a5W4adurkdUUiPlNQS/jYscPtgPfjjzB5Mtxwg9cVifiFglrCw48/upDetcstZMllvr5IqFJQS+j77jsX0unpbkl4gwZeVyTiV5r1IaFt2TJo0sQ9X7BAIS1hSUEtoWvePLj2WihTBr75BnRogoQpBbWEpilT3OyOKlVcSFer5nVFIgGjoJbQM3IktGsHdevC11/Dued6XZFIQCmoJbQMGwbdusHVV7ujs7SXtEQABbWEBmvhmWfgscdcb3r6dChVyuuqRAqFglqCX0YG3H8/vPiiWw4+fjyccYZfmi49oDT3TL2HpduX+qU9kUBQUEtwS0+Hzp3hnXegTx/3NirKb80fPHKQ+anzafRBIy4ZfglvLHuDfX/s81v7Iv6goJbgdeCAWwY+cSIMHgz9+/t9BzxjDIvuXkRy92TiK8bz9JynOXfIudzx2R0kb0v262uJFJSCWoLT7t3uhuH8+W6WR+/eAXmZ7IMzEs9PJOmmJHb03sHL173M2l1ruSrpKv75xj8Zsijn8WkihUlBLcFn61ZITIT169186TvuCNhLmVN66GeecSYPNniQb+/9lsV3L6bx+Y35z4L/BOz1RfJCe31IcFm1yi1kSU930++uuCKgL3e6o+gaVmpIw0oNGdZiWEBrEPk76lFL8PjqK7dvR9GisHBhwEMa4M66d1I8uvhpP6ZUjKYBircU1BIcxo2DFi3g/PNh0SKoUaNQXvbDth9S+ozShfJaIgWloBZvWevONOzcGRo1csdnVarkaUnLf1nOJ+s/IWVHiqd1iGTTGLV4JzPTzeYYNgzat4dRo6BYsUItoe/cvjSp0oQWF7Zg98HdtBnXhqXblxJdJJpjmcdoVLkRkztOpnzJ8oVal8iJ1KMWbxw+DB06uJB+9FE39FHIIQ0wcvVIKpaqCMCTs5/EWsvGhzZy5NkjbH54M0WLFKX3rMBMDRTJK/WopfClpUHbtrB4Mbzyitu/wyN7Du2hTLEyACzYtoCPb/6Yi8pdBMAFZS9g6PVDaTm6pWf1iYB61FLYtmxxc6RXrIAJEzwNaYCq/6jKul3rAChicv5zMMZw+Njhwi5L5CQKaik8CxfC5ZfDnj3ubMNbb/W6Iu6tdy9PzHqCTXs28XCDh3li9hNs2bsFgK2/beWxLx+jxYUtPK5SIp2GPqRwjBvn9pE+/3yYMQMuusjrigDodXkvftr/E7Xfqs0FZS8gdV8qF79x8fGbifEV4xnXbpzXZUqEU1BLYFnrtid99llo3BgmT4Zy5byu6iSvXP8K99a7l6kbp/Ljbz+SaTOpWLoiiZUTaVatWY5l5iKFTUEtgZOeDvfcAx9/DLfdBh984MnMjryoHludJ2Of9LoMkVxpjFoCY/dud0L4xx/D88+7t0Ea0iLBTj1q8b+1a6FNG/j1Vzc23bGj1xUVWLNRzdi6bytbHtnidSkSwRTU4l9Tp0KXLlC6NCxYAA0aeF2RT+qfW5/KZSp7XYZEOAW1+Ie1MHAg9O0L9eq5m4bnned1VT4b0GyA1yWIKKjFDw4dgrvucofOdurkbhqWKOF1VSJhQzcTxTfbtrmVhhMmwEsvwZgxIRfS+/7Yx4xNM1j086IcBwkcPHKQ5xc871FlIo6CWgruq68gIcEdnTV9Ovzf//n98NlA+27Xd9R4swZtx7Wl8YjG1H+vPtv2bTt+/X9H/qejuMRzCmrJP2vdqeDXXQdnnw3LlkGrVl5XVSB95vahUaVG7H96P788/gvV/lGNxBGJbN6z2evSRI5TUEv+/O9/bhz6ySfhlltgyRK4+GKvqyqwJduX8MLVL1AypiQVS1dkQvsJdKjVgaYjm7JpzyavyxMBdDNR8uP776FdO9i40Y1HP/VUyA11nCo9Iz3HEvFXrn8Fay1XJV3F2HZjPapM5E8Kasmb8ePh7ruhZEmYPRuuucbrivyiernqpOxIoWb5mie9f2iLoWTaTNqOa+tRZSJ/0tCHnN4ff8BDD7nhjrp1YeXKsAlpgJv/eTNj1+Xea3615at0rdM1x0wQkcJmAvFDmJCQYFNSdDBoyNuyxR2XtXKlO9twwAAoWtTrqgqsaVJTAOZ3m+9pHSK5McassNYm5HZNQx+SuwkToEcPiIpyy8JvvNHrikQiloY+5GQHD7qA7tgRatSAb7+NmJB+6ZuX2PfHvhzPRbymoJY/rV7tFrB88AH06QPJyVClitdVFZr+yf3Ze3hvjuciXlNQC2RmwtChbqe7fftg1izo3z+kx6MLwmJzfS7iNY1RR7odO+DOO2HOHLeH9PvvQ/nyXlclIidQjzqSjR8PtWvDokXwzjtua1KFtEjQUVBHor173RmGnTq508BXroSePUN+laFIuFJQR5oZM6BOHZg4EV54ARYuhOrVva5KRE5DQR0pfvvNjUW3bg1ly8LSpfDMMxCt2xQiwU5BHQkmT4ZatWD0aBfOK1ZAfLzXVYlIHqk7Fc527oSHH4ZPPoFLL3Wb+yug/9LMLjM5r/R5OZ6LeE096nCUmelmcdSs6cK5f39YvlwhfRqffv8pjc9vzBnRZwCc9HzgNwO9LE1EQR121q6Fxo3hvvtcL3r1arfKMMIWr+RXl0+7cM/Uezh09NDx923/fTtNk5oydMlQDysTUVCHjwMH3Kkr8fGwaRMkJcG8eZrRkUdL71nKku1LqPt2XVJ2pDB+3XjqDK9D8aLFWX3faq/LkwinMepQZ61buNK7t1tleNddMHAgxMZ6XVlIueScS0jpmcIDMx6g0QeNMBgGNx/MIw0f8bo0EfWoQ9rq1W4T/86doUIFWLzYbaikkC6Q1b+uZsG2BVxY9kJiomJY9ssyDqQf8LosEQV1SNq9241Bx8e7Mem33nIngV9+udeVhawXFrxAk6QmtK3eltX3rWZFzxVs3LOROsPrkLwt2evyJMIpqEPJH3+4YY0LL3SbJz38MGzeDPff7zb4lwIbnjKcaZ2n8cr1rxATFUP12OosvnsxnWp3otlHzbwuTyKcxqhDQWYmjBsHffvCtm1udeGgQW5jf/GLNfevIbbEyUNG0UWieanZS7S6qJVHVYk46lEHM2vhiy+gXj3o0sUt/Z47F6ZNU0j72akhfaImVZoUYiUiOSmog9XChe5GYcuWsH+/W/6dkhJWJ4CLSN4oqINNSooL58aNYf16eO012LDBbUtaRN8ukUikf/nBYtkyd4hs/fru+cCB8OOP7oZhTIzX1YmIh3Qz0WvffAMvvujGosuWdXtEP/IInHmm15WJSJBQUHvBWvj8cxgwwI1Fx8bCSy/BAw9A6dJeVyciQUZBXZiOHIGxY2HIELdQpXJlePVVuOceKFHC6+pEJEgpqAvDnj3w3nvw+utuP47ateHDD90NQo0/i8jfUFAH0tq1btbGxx+7VYXNmsGIEdC8uQ6SFZE8U1D725Ej7kSV4cMhORmKF4c77nCzN2rX9ro6EQlBCmp/2bzZ7b+RlAS7dsEFF8DLL0P37lCunNfViUgIU1D74tAh+PRTN5wxb57bGKl1a7dJ0nXXaYGKiPiFgjq/MjPdlLpRo9yG/QcOQLVqbi50t25w7rleVygiYUZBnVfr17v9NkaPdjvYlSwJ7du7oY3GjdV7FpGAUVCfzg8/uF7zuHGwbp0L4+bNXe+5bVsoVcrrCkUkAiioT2QtfP+9m7UxaRKsWePe37ixmwN9663uyCsRkUKkoM7IgCVLYMoUmDzZzd4wBhITYehQaNfOrSAUEfFIZAb13r0waxbMmAEzZ7qVg0WLur2eH3vMDWvopqCIBInICOpjx9w+z7NmuV3qli51szfKlYNWreCGG6BFCyhTxutKRURyCM+gtha++87Nbf7qK/d2/343pFG/PjzzjAvmBg10KKyIBL3wCOqMDLevRnIyfP01LFgAu3e7a1WrQocObgHK1Ve7LUVFREJIaAb1gQPuFJRFi9zikyVLXI8Z4PzzXW/56qvdIy7O01JFRHwV/EF95Iibw5yS4sJ56VI3rGGtG8qoVQs6doQrr3SPKlW8rlhExK+CK6gPHXKhvGoVrFzpHmvWQHq6u162LDRs6FYENmzoHmed5WXFIiIB501QZ2TA1q0ulNeudW9Xr3ZzmDMz3cecdRbEx8NDD7kbgPXru/Fm7eMsIhGm8IJ6yxb417/csMWGDW4j/WzVqkGdOtCpE1x6KdSt68aWFcoiIoUY1FFRbkZGrVpuYUnNmm4j/Vq1tGeGiMhpFF5Qx8XBTz8V2suJiIQL7c0pIhLkFNQiIkFOQS1+dzD9GNbaXK9ZazmYfkxtiuSDglr86mD6MTq+u5jnp6/PEVjWWp6fvp6O7y7OV2BFcpsikMegNsa0MMZsNMb8YIx5OtBFSegqERNF/biyfLgw9aTAyg6qDxemUj+uLCVi8r4ZViS3KQJ5mPVhjIkC3gSuA7YDy40xU6216wNdnIQeYwzPta4JwIcLUwF4rnXN40HVPTGO51rXxORjjnwktykCeZue1wD4wVr7I4AxZhzQFlBQS65ODazs0PIlqCK5TZG8DH2cB/x8wp+3Z73vJMaYnsaYFGNMyu7sLUYlYp0YWNl8DSpf25zfbT7zu80P+jpFTpWXoM7tpyvHbW1r7bvW2gRrbUL58uV9r0xCWva47Ilyu8mmNkX+Xl6Cejtw4umulYAdgSlHwsGJN8+6J8axdUAruifG5bjJpjZF8iYvY9TLgYuMMVWBX4BOwG0BrUpC1qlBlf0rf2432fI6FBDJbYpAHoLaWnvMGPMQ8CUQBYyw1n4X8MokJB06ksHy1L05bp6dGFjLU/dy6EgGJc/I21YzkdymCIAJxK9iCQkJNiUlxe/tSmg4mH6MEjFRufYarbUFCqpIblMigzFmhbU2Ibdr+okRvztdEBljChRUkdymiJaQi4gEOQW1iEiQU1CLiAS5gNxMNMbsBrb5vWEpDLFAmtpUm2qz0NurYq3NdbVgQIJaQpcxJuWv7jyrTbWpNgu/PdDQh4hI0FNQi4gEOQW1nOpdtak21WZQtacxahGRYKcetYhIkFNQi4gEOQW1HOfvQ4yNMSOMMbuMMev8UV9Wm5WNMfOMMd8bY74zxjzqhzaLGWOWGWNWZ7X5Hz/VGmWM+dYYM91P7aUaY9YaY1YZY/yy65kx5ixjzCRjzIasr2kjH9urnlVf9uN3Y0wvP9T5WNb3Zp0xZqwxppgf2nw0q73vClpjbj/jxpiyxpjZxpjNWW//4WutWGv10APcFrZbgGpADLAaqOljm02AeGCdH+usCMRnPS8NbPJDnQYolfW8KLAUuNwPtT4OjAGm++lzTwVi/fx9Hwnck/U8BjjLzz9Tv+IWcvjSznnAVqB41p8nAN18bLM2sA4ogducbg5wUQHayfEzDgwCns56/jQw0NevpXrUku34IcbW2iNA9iHGBWat/RrY64/iTmhzp7V2ZdbzA8D35HKGZz7btNba/2X9sWjWw6e77MaYSsANwPu+tBNIxpgzcUHzAYC19oi1dp8fX+JaYIu11h+rlKOB4saYaFy4+nrKVA1gibX2kLX2GLAAuDm/jfzFz3hb3H+AZL29yYc6AQ19yJ/ydIhxMDHGxAGX4XrAvrYVZYxZBewCZltrfW1zGPAUkOljOyeywCxjzApjTE8/tFcN2A18mDVE874xpqQf2s3WCRjrayPW2l+AwcBPwE5gv7V2lo/NrgOaGGPKGWNKAK04+chBX5xjrd0JrmMBnO1rgwpqyZanQ4yDhTGmFPAJ0Mta+7uv7VlrM6y1dXFngjYwxtT2obbWwC5r7Qpf6zpForU2HmgJPGiMaeJje9G4X9uHW2svAw7iflX3mTEmBmgDTPRDW//A9VKrAucCJY0xXX1p01r7PTAQmA18gRvqO+ZjqQGjoJZsIXOIsTGmKC6kR1trP/Vn21m/+s8HWvjQTCLQxhiTihtCusYY87EfatuR9XYX8BluuMoX24HtJ/z2MAkX3P7QElhprf2vH9pqBmy11u621h4FPgWu8LVRa+0H1tp4a20T3PDFZl/bzPJfY0xFgKy3u3xtUEEt2Y4fYpzVG+oETPW4phyMO+PqA+B7a+0rfmqzvDHmrKznxXHBsKGg7Vlr+1hrK1lr43Bfx6+stT71AI0xJY0xpbOfA81xv74XmLX2V+BnY0z1rHddC6z3pc0TdMYPwx5ZfgIuN8aUyPr+X4u7N+ETY8zZWW/PB27Bf/VOBe7Men4nMMXXBnUukACBOcTYGDMWaArEGmO2A/+y1n7gY6mJwO3A2qwxZYC+1trPfWizIjDSGBOF67xMsNb6ZUqdH50DfJZ1FmM0MMZa+4Uf2n0YGJ31n/OPQHdfG8wa870OuNfXtgCstUuNMZOAlbjhiW/xzzLtT4wx5YCjwIPW2t/y20BuP+PAS8AEY8zduP9k2vtaqJaQi4gEOQ19iIgEOQW1iEiQU1CLiAQ5BbWISJBTUIuIBDkFtYhIkFNQi4gEuf8H5GfctidT6LgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data points\n",
    "plt.scatter(X, y, marker='x', s=70) \n",
    "plt.xticks(np.arange(0,11))\n",
    "plt.yticks([0,1])\n",
    "\n",
    "# Generate points to plot the logistic regression line\n",
    "X_ = np.linspace(-5,10,100).reshape((-1,1))\n",
    "z = b + w * X_\n",
    "f = 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Plot logistic regression line\n",
    "plt.plot(X_, f, 'r')\n",
    "\n",
    "# Calculate the decision boundary\n",
    "db = -b/w  # decision boundary\n",
    "db = db.squeeze()\n",
    "print('decision boundary =', '%.2f' %db)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.hlines(0.5, min(X_), db, linestyles='dashed', colors='k', )\n",
    "plt.vlines(db, 0, 1, colors='g')\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(-1, .55, 'y=0.5', fontsize=14)\n",
    "plt.text(db+.15, 0.2, 'x='+'{:.2f}'.format(db),\n",
    "         fontsize=14, rotation='vertical', c='g')\n",
    "\n",
    "# Set x-axis limit\n",
    "plt.xlim([db-8, db+8])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb715bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b26c5",
   "metadata": {},
   "source": [
    "In logistic regression, `predict_proba(X)` returns the probability estimates for all classes (in this case, the probability of belonging to class 0 and class 1) for each input sample X.\n",
    "\n",
    "The first column is the probability of the predicted output being 0, that is 1-p(x), and the The second column is the probability that the output is 1, or p(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9647ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66062114 0.33937886]\n",
      " [0.56615102 0.43384898]\n",
      " [0.46661605 0.53338395]\n",
      " [0.36966975 0.63033025]\n",
      " [0.2822085  0.7177915 ]\n",
      " [0.20859222 0.79140778]\n",
      " [0.15016198 0.84983802]\n",
      " [0.10590872 0.89409128]\n",
      " [0.07356807 0.92643193]\n",
      " [0.05054479 0.94945521]] \n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 1] actual\n",
      "[0 0 1 1 1 1 1 1 1 1] prediction\n"
     ]
    }
   ],
   "source": [
    "# Print the probability estimates for all classes\n",
    "print(model.predict_proba(X), '\\n') \n",
    "\n",
    "# Print the actual class labels\n",
    "print(y, 'actual')\n",
    "\n",
    "# Print the predicted class labels\n",
    "print(model.predict(X), 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522fb4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Accuracy: ratio of the number of correct predictions to the number of observations\n",
    "print(model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82634a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y, model.predict(X)))  # confusion matrix\n",
    "\n",
    "# True negatives in the upper-left position\n",
    "# False negatives in the lower-left position\n",
    "# False positives in the upper-right position\n",
    "# True positives in the lower-right position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c9c0d",
   "metadata": {},
   "source": [
    "Let's set different parameters for regularization.\n",
    "\n",
    "Parameter `C` is inverse of regularization strength, smaller values specify stronger regularization. We want to increase it to weaken regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc7906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: [-3.81588578]\n",
      "w: [[0.93405685]]\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=10)\n",
    "\n",
    "# Fit the logistic regression model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "print('b:', model.intercept_)\n",
    "print('w:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07d090",
   "metadata": {},
   "source": [
    "As you can see, the absolute values of the intercept $b$ and the coefficient $w$ are larger. This is the case because the larger value of `C` means weaker regularization, or weaker penalization related to high values of $b$ and $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e17e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision boundary = 2.67\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data points\n",
    "plt.scatter(X, y, marker='x', s=70) \n",
    "plt.xticks(np.arange(0,11))\n",
    "plt.yticks([0,1])\n",
    "\n",
    "# Generate points to plot the logistic regression line\n",
    "X_ = np.linspace(-5,10,100).reshape((-1,1))\n",
    "z = b + w * X_\n",
    "f = 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Plot logistic regression line\n",
    "plt.plot(X_, f, 'r')\n",
    "\n",
    "# Calculate the decision boundary\n",
    "db = -b/w  # decision boundary\n",
    "db = db.squeeze()\n",
    "print('decision boundary =', '%.2f' %db)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.hlines(0.5, min(X_), db, linestyles='dashed', colors='k', )\n",
    "plt.vlines(db, 0, 1, colors='g')\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(-1, .55, 'y=0.5', fontsize=14)\n",
    "plt.text(db+.15, 0.2, 'x='+'{:.2f}'.format(db),\n",
    "         fontsize=14, rotation='vertical', c='g')\n",
    "\n",
    "# Set x-axis limit\n",
    "plt.xlim([db-8, db+8])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8d638",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "Let's build the diabetes prediction model. Here, you are going to predict diabetes using the Logistic Regression Classifier. Let's first load the required Pima Indian Diabetes dataset using the pandas' read CSV function. You can download data from the this [link](https://www.kaggle.com/uciml/pima-indians-diabetes-database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3151f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima = pd.read_csv('diabetes.csv') #, header=None, names=col_names)\n",
    "pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9e79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in features and target variable\n",
    "feature_cols = ['Pregnancies', 'Glucose', 'BloodPressure',\n",
    "                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.Outcome       # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19cca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42cb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Perediction on test data\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19832d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7760\n",
      "[[112  12]\n",
      " [ 32  36]]\n"
     ]
    }
   ],
   "source": [
    "# The ratio of the number of correct predictions to the number of observations\n",
    "print('accuracy = %.4f' %logreg.score(X_train, y_train))\n",
    "\n",
    "# Confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de511893",
   "metadata": {},
   "source": [
    "**Confusion Matrix:**\n",
    "\n",
    "|                     | Predicted Negative  | Predicted Positive  |\n",
    "|:----------------    |:--------------------|:--------------------|\n",
    "| **Actual Negative** | True Negative (TN)  | False Positive (FP) |\n",
    "| **Actual Positive** | False Negative (FN) | True Positive (TP)  |\n",
    "\n",
    "\n",
    "- **Accuracy**:\n",
    "   - Accuracy measures the overall correctness of the classifier. It's the ratio of correctly predicted instances to the total instances.\n",
    "   \n",
    "   $$ \\small\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} $$\n",
    "    \n",
    "\n",
    "- **Recall (Sensitivity) or (True Positive Rate) or (1 $-$ type II error)**:\n",
    "   - Recall measures the proportion of true positive predictions among all actual positive instances in the dataset.\n",
    "   - It answers the question: \"Out of all actual positive instances, how many were predicted correctly?\"\n",
    "   - Use recall when the cost of false negative is high, such as fraud detection or medical diagnosis.\n",
    "   \n",
    "   $$\\small\\text{recall} = \\frac{\\text{TP}} {\\text{TP + FN}}$$\n",
    "\n",
    "- **Precision**:\n",
    "   - Precision measures the proportion of true positive predictions among all positive predictions made by the classifier.\n",
    "   - It answers the question: \"Out of all instances predicted as positive, how many are actually positive?\"\n",
    "   - Use precision when the cost of false positive is high, such as classifying spams.\n",
    "   \n",
    "   $$\\small\\text{precesion} = \\frac{\\text{TP}} {\\text{TP + FP}}$$\n",
    "\n",
    "- **F1-score**:\n",
    "   - The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
    "   - F1-score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "   - It's a useful metric when the classes are imbalanced.\n",
    "   $$ \\small\\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
    "   \n",
    "- **Specificity or (True Negative Rate) or (1 $-$ type I error):**\n",
    "    - The classifier's ability to correctly identify negative instances out of all actual negative instances.\n",
    "    \n",
    "    $$\\small\\text{specificity} = \\frac{\\text{TN}} {\\text{TN + FP}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00beebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84bd0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.77\n",
      "recall = 0.53\n",
      "precision = 0.75\n",
      "f1_score = 0.62\n",
      "specificity = 0.90\n"
     ]
    }
   ],
   "source": [
    "print('accuracy = %.2f'    %accuracy)\n",
    "print('recall = %.2f'      %recall)\n",
    "print('precision = %.2f'   %precision)\n",
    "print('f1_score = %.2f'    %f1_score)\n",
    "print('specificity = %.2f' %specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfb008",
   "metadata": {},
   "source": [
    "Or you can use `metrics.classification_report(y_test, y_pred)` to report all of these measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1feb728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       124\n",
      "           1       0.75      0.53      0.62        68\n",
      "\n",
      "    accuracy                           0.77       192\n",
      "   macro avg       0.76      0.72      0.73       192\n",
      "weighted avg       0.77      0.77      0.76       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
